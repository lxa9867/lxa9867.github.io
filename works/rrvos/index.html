
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>R^2VOS: Robust Referring Video Object Segmentation via Relational Multimodal Cycle Consistency</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

        <!--FACEBOOK-->
    <meta property="og:image" content="https://choyingw.github.io/works/Voice2Mesh/img/teaser.png">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="682">
    <meta property="og:image:height" content="682">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://lxa9867.github.io/proj_pages/rrvos/index.html"/>
    <meta property="og:title" content="R^2VOS" />
    <meta property="og:description" content="R^2VOS: Robust Referring Video Object Segmentation" />



<!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
  <!-- <link rel="icon" type="image/png" href="img/seal_icon.png"> -->
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                R^2VOS: Robust Referring Video Object Segmentation via Relational Multimodal Cycle Consistency</br>
                <small>
                    arXiv
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a>
                          Xiang Li
                        </a>
                        </br>CMU
                    </li>
                    <li>
                        <a>
                            Jinglu Wang
                        </a>
                        </br>MSRA
                    </li>
                    <li>
                        <a>
                            Xiaohao Xu
                        </a>
                        </br>HUST
                    </li>
                    <li>
                        <a>
                            Xiao Li
                        </a>
                        </br>MSRA
                    </li>
                         <li>
                        <a>
                            Yan Lu
                        </a>
                        </br>MSRA
                    </li>
                    <li>
                        <a>
                            Bhiksha Raj
                        </a>
                        </br>CMU
                    </li>
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
<!--                            <a href="https://arxiv.org/abs/2203.09824">-->
                            <a>
                            <image src="img/paper_image.png" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a>
                            <image src="img/github_pad.png" height="60px">
                                <h4><strong>Code and Data (coming)</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <center>
                    <iframe width="800" height="450" src="https://www.youtube.com/embed/xzL8olvgqRY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
                    </iframe>
                </center>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <image src="img/teaser.jpg" class="img-responsive" alt="overview"><br>
                <p class="text-justify">
                    Referring video object segmentation (R-VOS) aims to segment the object masks in a video given a referring linguistic expression to the object. It is a recently introduced task attracting growing research attention. However, all existing works make a strong assumption: The object depicted by the expression must exist in the video, namely, the expression and video must have an object-level semantic consensus. This is often violated in real-world applications where an expression can be queried to false videos, and existing methods always fail in such false queries due to abusing the assumption. In this work, we emphasize that studying semantic consensus is necessary to improve the robustness of R-VOS. Accordingly, we pose an extended task from R-VOS without the semantic consensus assumption, named Robust R-VOS (R^2-VOS). The R^2-VOS task is essentially related to the joint modeling of the primary R-VOS task and its dual problem (text reconstruction). We embrace the observation that the embedding spaces have relational consistency through the cycle of text-video-text transformation, which connects the primary and dual problems. We leverage the cycle consistency to discriminate the semantic consensus, thus advancing the primary task. Parallel optimization of the primary and dual problems are enabled by introducing an early grounding medium. A new evaluation dataset, R^2-Youtube-VOS, is collected to measure the robustness of R-VOS models against unpaired videos and expressions. Extensive experiments demonstrate that our method not only identifies negative pairs of unrelated expressions and videos, but also improves the segmentation accuracy for positive pairs with a superior disambiguating ability. Our model achieves the state-of-the-art performance on Ref-DAVIS17, Ref-Youtube-VOS, and the novel R^2-Youtube-VOS dataset. </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
				<h3>Citation</h3>
				<p class='bibtex'>@inproceedings{Li2022R^2VOS,<br>
                    title={R^2VOS: Robust Referring Video Object Segmentation via Relational Multimodal Cycle Consistency},<br>
                    author={Xiang Li, Jinglu Wang, Xiaohao Xu, Xiao Li, Yan Lu, Bhiksah Raj},<br>
                    booktitle={arXiv},<br>
                    year={2022}}</p>
		<br>
            </div>
        </div>

<!--		<p class="banner"align="center">Powered by <a href="https://williamyang1991.github.io/">Shuai Yang</a></p>-->
  </div>
    
</body>
</html>
